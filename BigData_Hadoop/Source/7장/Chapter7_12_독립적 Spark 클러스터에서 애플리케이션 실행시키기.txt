<독립적 Spark 클러스터에서 애플리케이션 실행시키기>

# spark-submit --help
Usage: spark-submit [options] <app jar | python file> [app arguments]
Usage: spark-submit --kill [submission ID] --master [spark://...]
Usage: spark-submit --status [submission ID] --master [spark://...]
Options:
  --master MASTER_URL         spark://host:port, mesos://host:port, yarn, or
local.
  --deploy-mode DEPLOY_MODE   Whether to launch the driver program locally
("client") or
                              on one of the worker machines inside the cluster
("cluster")
 ...




$ /path/to/spark/bin/spark-submit --deploy-mode cluster \
                                  --master <master-URL> \
                                  </path/to/app-jar> [app-arguments]



$ /path/to/spark/bin/spark-submit --status <submission-id>