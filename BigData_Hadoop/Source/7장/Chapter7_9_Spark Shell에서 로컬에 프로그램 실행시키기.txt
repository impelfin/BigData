<Spark Shell에서 로컬에 프로그램 실행시키기: spark-shell로 싱글노드에 WordCount 프로그램을 로컬에 실행시키는 방법>


$ spark-shell
16/04/27 12:52:19 INFO HttpServer: Starting HTTP Server
Welcome to
      ____              __
     / __/__ ___ _____/ /__
    _\ \/ _ \/ _ '/ __/ '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.3.0
      /_/

Using Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_45)
Type in expressions to have them evaluated.
Type :help for more information.
16/04/27 12:52:24 INFO SparkContext: Running Spark version 1.3.0
16/04/27 12:52:25 INFO Utils: Successfully started service 'sparkDriver' on
port 29755.
16/04/27 12:52:26 INFO SparkUI: Started SparkUI at http://hadoop09.example
.com4040
16/04/27 12:52:27 INFO Client: Will allocate AM container, with 896 MB memory
including 384 MB overhead
16/04/27 12:52:27 INFO Client: Submitting application 2992 to ResourceManager
16/04/27 12:52:41 INFO SparkILoop: Created sql context (with Hive support)..
SQL context available as sqlContext.

scala>

scala> val words = sc.textFile("hdfs://localhost:9000/user/hduser/words")



scala> val wordsFlatMap = words.flatMap(_.split(\\w+))



scala> val wordsMap = wordsFlatMap.map(w => (w, 1))



scala> val wordCount = wordsMap.ReduceByKey ( (a,b) => a+b))



scala> val wordCountSorted = wordcount.sortByKey (true)



scala> wordCountSorted.collect.foreach (println)



Scala> sc.textFile("hdfs://localhost:9000/user/hduser/words").flatMap(_.split(\\w+)).map (w => (w, 1)).reduceByKey((a,b) => a+b)).sortByKey(true).collect.foreach(println)